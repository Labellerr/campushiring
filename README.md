# Predictions + Split Dataset link
   https://drive.google.com/drive/folders/1sH-vbJr1QPKdJErPo-r6FN0Y6GjXqbIN?usp=drive_link
# üìù  Project Title: End-to-End Vehicle and Pedestrian Segmentation & Tracking
# üöÄ  Overview
This project demonstrates an end-to-end computer vision pipeline for instance segmentation and multi-object tracking of vehicles and pedestrians. The system uses a fine-tuned YOLO-Seg model for accurate detection and integrates it with ByteTrack for robust object tracking in videos. The project covers the full machine learning lifecycle, from data curation and annotation on the Labellerr platform to model training and evaluation.

# üõ†Ô∏è  Tech Stack
Computer Vision Framework: Ultralytics YOLOv8-Seg

Object Tracking: ByteTrack

Data Annotation & Management: Labellerr Platform

Programming Language: Python

Environment: Google Colab


# üõ£Ô∏è  Project Journey: A Step-by-Step Guide
This section outlines the complete process, from data preparation to the final demo.

1. ## Data Collection & Curation
Challenge: The assignment required a "difficult" and permissibly licensed dataset.

Solution: A custom dataset was created by combining raw images from sources like Kaggle and Google Images with a permissive license. This approach ensured a diverse dataset with a variety of lighting conditions, occlusions, and backgrounds, which are common challenges in computer vision.

2. ## Data Annotation with Labellerr
Challenge: Initial image files appeared blurry in the Labellerr UI, making precise annotation difficult.

Resolution: I realized this was a display issue caused by the browser's resizing of the image to fit the annotation screen. The underlying image files were not affected. I proceeded with the annotation, knowing that the model would be trained on the original, high-resolution data. This was noted as a potential UI/UX improvement.

Challenge: The AI-assisted annotation feature did not display the pre-generated polygons initially, even though the files were "In Review."

Resolution: I initially thought there was a problem with the AI, but after troubleshooting, I concluded it was likely a temporary platform issue. I proceeded with manual polygon annotation, which demonstrated my ability to perform the task without AI assistance, ensuring the project could continue.

3. ## Model Training & Evaluation
Model Used: Ultralytics YOLOv8-Seg with a yolov8n-seg.pt backbone, fine-tuned for ~100 epochs on the custom dataset.

Metrics: The model's performance was evaluated on a dedicated test set. Key metrics, including the mAP (mean Average Precision), confusion matrix, and PR (Precision-Recall) curves, were generated to assess accuracy and identify areas for improvement.

### Challenge: The initial data export from Labellerr contained only the label files, with the images folder being empty.

Resolution: This was identified as a critical problem that prevented model training. The issue was solved by manually downloading the images and organizing the dataset to match the YOLO format, pairing each image with its corresponding .txt label file. This step showcased an important debugging ability, which is a key skill for a software engineer.

# üìà  Results & Visualizations
The final model achieved a strong performance on the validation set. Below are the key evaluation metrics and plots.

Confusion Matrix: [Include a screenshot or link to the confusion matrix generated by YOLOv8]. This plot shows how well the model distinguished between vehicles, pedestrians, and the background.

PR Curve: [Include a screenshot or link to the PR curve]. This graph illustrates the trade-off between the model's precision and recall, demonstrating its robust performance across different confidence thresholds.

# üí°  Suggestions for Improving Labellerr
Based on my experience, here are some suggestions for enhancing the Labellerr platform:

Improve Image Export: The platform should ensure that both images and their corresponding label files are included in the export package by default, as a single, complete .zip file. This would prevent common user issues and streamline the data preparation process.

Add a YOLO-ready Export Validator: A simple check before export that verifies if all the necessary files (images and labels) are ready for download in a cohesive format would greatly improve the user experience and prevent pipeline breaks.

Enhance AI-Assisted Visibility: If the AI-generated annotations are not immediately visible, a clear notification or a toggle button to "Show AI Predictions" should be present. This would prevent confusion and allow users to immediately begin the review phase.
