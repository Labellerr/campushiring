{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"9f8iJfmYn5eX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1758566015699,"user_tz":-330,"elapsed":484,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"62171db6-42e9-4a45-98db-6addf1bfa875","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Mon Sep 22 18:33:35 2025       \n","+-----------------------------------------------------------------------------------------+\n","| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n","|-----------------------------------------+------------------------+----------------------+\n","| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n","|                                         |                        |               MIG M. |\n","|=========================================+========================+======================|\n","|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n","| N/A   44C    P8             11W /   70W |       0MiB /  15360MiB |      0%      Default |\n","|                                         |                        |                  N/A |\n","+-----------------------------------------+------------------------+----------------------+\n","                                                                                         \n","+-----------------------------------------------------------------------------------------+\n","| Processes:                                                                              |\n","|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n","|        ID   ID                                                               Usage      |\n","|=========================================================================================|\n","|  No running processes found                                                             |\n","+-----------------------------------------------------------------------------------------+\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","source":["!pip3 install ultralytics"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kBwEI1p3Q5fr","executionInfo":{"status":"ok","timestamp":1758566029957,"user_tz":-330,"elapsed":8766,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"8331e807-a5d1-4bec-e424-62a4328b380b","collapsed":true},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ultralytics\n","  Downloading ultralytics-8.3.203-py3-none-any.whl.metadata (37 kB)\n","Requirement already satisfied: numpy>=1.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.0.2)\n","Requirement already satisfied: matplotlib>=3.3.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (3.10.0)\n","Requirement already satisfied: opencv-python>=4.6.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (4.12.0.88)\n","Requirement already satisfied: pillow>=7.1.2 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (11.3.0)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (6.0.2)\n","Requirement already satisfied: requests>=2.23.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.32.4)\n","Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.16.2)\n","Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (2.8.0+cu126)\n","Requirement already satisfied: torchvision>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from ultralytics) (0.23.0+cu126)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ultralytics) (5.9.5)\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (from ultralytics) (1.25.2)\n","Collecting ultralytics-thop>=2.0.0 (from ultralytics)\n","  Downloading ultralytics_thop-2.0.17-py3-none-any.whl.metadata (14 kB)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.3.3)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (4.60.0)\n","Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (1.4.9)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (25.0)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (3.2.4)\n","Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib>=3.3.0->ultralytics) (2.9.0.post0)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.23.0->ultralytics) (2025.8.3)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch>=1.8.0->ultralytics) (3.4.0)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib>=3.3.0->ultralytics) (1.17.0)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=1.8.0->ultralytics) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n","Downloading ultralytics-8.3.203-py3-none-any.whl (1.1 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ultralytics_thop-2.0.17-py3-none-any.whl (28 kB)\n","Installing collected packages: ultralytics-thop, ultralytics\n","Successfully installed ultralytics-8.3.203 ultralytics-thop-2.0.17\n"]}]},{"cell_type":"code","source":["from ultralytics import YOLO"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9ExcU4xLQ85n","executionInfo":{"status":"ok","timestamp":1758566040939,"user_tz":-330,"elapsed":6532,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"681edbe4-5293-4283-c3bf-da4e708d803b"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Creating new Ultralytics Settings v0.0.6 file ✅ \n","View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n","Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"]}]},{"cell_type":"code","source":["folder_Path_drive = \"Datasets/PV3\"\n","from google.colab import drive\n","drive.mount(\"/content/gdrive\")\n","!cp /content/gdrive/MyDrive/{folder_Path_drive}/data.zip /content"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xCWp-qWSRB2s","executionInfo":{"status":"ok","timestamp":1758566073666,"user_tz":-330,"elapsed":29420,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"dab383a5-783c-4c1d-f9cc-11653e194da0"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive\n"]}]},{"cell_type":"code","source":["%cd /content\n","!unzip -q data.zip -d /content/Data\n","# Unzip your dataset from Google Drive\n","# !unzip /content/drive/MyDrive/path/to/your/dataset.zip -d /content/yolov8_data"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wWkqY0ujRKuU","executionInfo":{"status":"ok","timestamp":1758566077668,"user_tz":-330,"elapsed":908,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"fcf5b978-5c04-49d1-c72f-150456d53f5b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}]},{"cell_type":"code","source":["# patience - if 25 iterations have passed and there are no improvements then terminate the prg\n","# !yolo task=detect mode=train model=yolov8m.pt data=../content/Data/data.yaml epochs=300 imgsz=640 patience=25\n","# !yolo task=detect mode=train model=yolov8l.pt data=../content/Data/data.yaml epochs=100 imgsz=640 patience=25 save_period=5 project=\"/content/gdrive/My Drive/Yolo_Checkpoints/peds_vehicles\"\n","# !yolo task=detect mode=train model=yolov8m.pt data=../content/Data/data.yaml epochs=100 imgsz=640 patience=25 save_period=5 project=\"/content/gdrive/My Drive/Yolo_Checkpoints/peds_vehicles\"\n","%cd /content\n","!yolo task=detect mode=train model=yolov8l.pt data=../content/Data/data.yaml epochs=100 imgsz=640 patience=25 save_period=5 project=\"/content/gdrive/My Drive/Yolo_Checkpoints/PV3\"\n","# !yolo task=detect mode=train model=yolov8l.pt data=../content/Data/data.yaml epochs=150 imgsz=640 patience=50 save_period=5 project=\"/content/gdrive/My Drive/Yolo_Checkpoints/peds_vehicles\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"yUMXhPM1RQ-m","executionInfo":{"status":"ok","timestamp":1758508761953,"user_tz":-330,"elapsed":3274582,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"a94cc562-20e0-4a18-baa6-db837bf6b0d1","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n","\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8l.pt to 'yolov8l.pt': 100% ━━━━━━━━━━━━ 83.7MB 92.0MB/s 0.9s\n","Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cpu CPU (AMD EPYC 7B13)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=16, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=../content/Data/data.yaml, degrees=0.0, deterministic=True, device=cpu, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=100, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8l.pt, momentum=0.937, mosaic=1.0, multi_scale=False, name=train, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=25, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/gdrive/My Drive/Yolo_Checkpoints/PV3, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train, save_frames=False, save_json=False, save_period=5, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=True, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=8, workspace=None\n","\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% ━━━━━━━━━━━━ 755.1KB 17.7MB/s 0.0s\n","Overriding model.yaml nc=80 with nc=2\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n","  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n","  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n","  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n","  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n","  7                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n","  8                  -1  3   4461568  ultralytics.nn.modules.block.C2f             [512, 512, 3, True]           \n","  9                  -1  1    656896  ultralytics.nn.modules.block.SPPF            [512, 512, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  3   1247744  ultralytics.nn.modules.block.C2f             [768, 256, 3]                 \n"," 16                  -1  1    590336  ultralytics.nn.modules.conv.Conv             [256, 256, 3, 2]              \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  3   4592640  ultralytics.nn.modules.block.C2f             [768, 512, 3]                 \n"," 19                  -1  1   2360320  ultralytics.nn.modules.conv.Conv             [512, 512, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  3   4723712  ultralytics.nn.modules.block.C2f             [1024, 512, 3]                \n"," 22        [15, 18, 21]  1   5584342  ultralytics.nn.modules.head.Detect           [2, [256, 512, 512]]          \n","Model summary: 209 layers, 43,631,382 parameters, 43,631,366 gradients, 165.4 GFLOPs\n","\n","Transferred 589/595 items from pretrained weights\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 2152.3±1194.1 MB/s, size: 84.6 KB)\n","\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Data/train/labels... 96 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 96/96 424.8it/s 0.2s\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/19-29-_jpg.rf.36aa72096306d3bb4cd646835b1a3161.jpg: 3 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/2-12-_jpg.rf.077edbb7754f11d2b590a4e2425c0054.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/2-23-_jpg.rf.b04d5885000ce7f797214c971122a3c4.jpg: 2 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/2-47-_jpg.rf.9cd1c6966ac59b32ea90fd9a52a33239.jpg: 3 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/20-104-_jpg.rf.1585baebf91901a554d054fb26e6456d.jpg: 2 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/Video4_18.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/Video4_9.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/Video5_4.jpg: 2 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/high-resolution_aerial_drone_photograph_looking_straight_down_at_a_complex_multi-level_highway_inte_h7avzt3eez2whosrrk6v_1.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/high-resolution_aerial_drone_photograph_looking_straight_down_at_a_complex_multi-level_highway_inte_yyu8xqr52qhoc6s4ifi6_0.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/photorealistic_street-level_view_of_a_busy_intersection_in_tokyo_at_night_during_a_heavy_downpour_n_963gha78zw7ocmesk7lj_5.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/photorealistic_street-level_view_of_a_busy_intersection_in_tokyo_at_night_during_a_heavy_downpour_n_d1y5lpvrt3m895lpn6ak_2.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/photorealistic_street-level_view_of_a_busy_intersection_in_tokyo_at_night_during_a_heavy_downpour_n_q144btxg52h1ld7vo8vk_3.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/photorealistic_street-level_view_of_a_busy_intersection_in_tokyo_at_night_during_a_heavy_downpour_n_qki9kzraa1ahmqa7jre5_0.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/photorealistic_street-level_view_of_a_busy_intersection_in_tokyo_at_night_during_a_heavy_downpour_n_y45ocbz2i9ee6onbmqec_4.png: 2 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/raw_dashcam_footage_still_looking_through_the_front_windshield_of_a_car_during_a_moderate_rainstorm_48t9fc1vf4xabiq5afs8_3.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/raw_dashcam_footage_still_looking_through_the_front_windshield_of_a_car_during_a_moderate_rainstorm_nw07cyx67618j0xmf80c_1.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0m/content/Data/train/images/ultra-realistic_photo_of_a_busy_urban_construction_zone_during_the_golden_hour_a_large_yellow_excav_klkoylxsfevuhr5xzz2n_0.png: 1 duplicate labels removed\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Data/train/labels.cache\n","\u001b[34m\u001b[1mval: \u001b[0mFast image access ✅ (ping: 0.0±0.0 ms, read: 3753.1±442.2 MB/s, size: 186.4 KB)\n","\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Data/val/labels... 8 images, 0 backgrounds, 0 corrupt: 100% ━━━━━━━━━━━━ 8/8 956.7it/s 0.0s\n","\u001b[34m\u001b[1mval: \u001b[0m/content/Data/val/images/Video7_40.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0m/content/Data/val/images/Video8_7.jpg: 1 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0m/content/Data/val/images/Video9_1.jpg: 6 duplicate labels removed\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Data/val/labels.cache\n","Plotting labels to /content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001667, momentum=0.9) with parameter groups 97 weight(decay=0.0), 104 weight(decay=0.0005), 103 bias(decay=0.0)\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1m/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train\u001b[0m\n","Starting training for 100 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      1/100         0G      1.147      2.537      1.071        444        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.703       0.52      0.594      0.395\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      2/100         0G     0.9941      1.131      1.023        362        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:37\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.5it/s 1.8s\n","                   all          8        266      0.624      0.601       0.57      0.383\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      3/100         0G     0.9302       0.89     0.9817        353        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.5it/s 1.9s\n","                   all          8        266      0.701      0.489      0.539      0.357\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      4/100         0G     0.9677     0.8388      1.022        365        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:37\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.725      0.449      0.507      0.354\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      5/100         0G     0.9896     0.8522     0.9945        420        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:36\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.746      0.483      0.551      0.372\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      6/100         0G     0.9582     0.9137      1.015        316        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:39\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.689       0.53       0.58      0.401\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      7/100         0G      1.017     0.9611      1.048        333        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:38\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.358      0.573      0.499      0.323\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      8/100         0G      1.007     0.8391      1.022        437        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:38\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.585      0.521       0.53       0.33\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K      9/100         0G      1.056     0.8619      1.057        374        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:38\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.453      0.378      0.378      0.239\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     10/100         0G      1.097     0.9382      1.097        472        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:40\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.595      0.385      0.447      0.295\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     11/100         0G      1.052     0.8532      1.061        554        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.5s\n","                   all          8        266      0.258      0.355       0.23      0.129\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     12/100         0G      1.083     0.8699      1.076        408        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:41\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.252      0.223      0.207      0.125\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     13/100         0G      1.098     0.8182      1.067        400        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.8s\n","                   all          8        266       0.16      0.236      0.137     0.0595\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     14/100         0G      1.055     0.7814      1.054        469        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.7s\n","                   all          8        266       0.27      0.202      0.175      0.087\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     15/100         0G      1.072     0.8129       1.07        416        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.7s\n","                   all          8        266       0.27      0.213      0.176     0.0915\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     16/100         0G      1.032     0.7909      1.059        402        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.312       0.31      0.242      0.145\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     17/100         0G      1.028     0.7877      1.051        475        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.399      0.325      0.256      0.173\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     18/100         0G      1.044     0.8676      1.076        389        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.455      0.366      0.307       0.18\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     19/100         0G     0.9784     0.7653      1.025        582        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.448       0.43      0.371      0.221\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     20/100         0G       1.04      0.779      1.064        319        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:48\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.5s\n","                   all          8        266      0.544      0.451      0.426      0.255\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     21/100         0G     0.9634     0.7574      1.035        383        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.421      0.411      0.397      0.263\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     22/100         0G       1.02     0.7439      1.042        359        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:47\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.7s\n","                   all          8        266      0.577       0.33      0.339      0.217\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     23/100         0G     0.9993     0.6911      1.046        365        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:47\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.7s\n","                   all          8        266      0.539      0.346      0.368      0.235\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     24/100         0G     0.9596     0.7037      1.009        334        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.641      0.332      0.382      0.259\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     25/100         0G     0.9424     0.7241      1.005        340        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:43\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266      0.531       0.44      0.428      0.283\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     26/100         0G     0.9385     0.7338      1.011        489        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:46\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.374      0.472      0.375      0.247\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     27/100         0G     0.9474     0.7149      1.019        323        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.6s\n","                   all          8        266       0.48      0.361       0.37      0.231\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     28/100         0G     0.9677     0.7534      1.027        295        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.726      0.422      0.518      0.324\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     29/100         0G     0.9458     0.7186      1.004        275        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.612      0.438      0.489      0.305\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     30/100         0G     0.8935     0.6394     0.9825        418        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:44\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.4s\n","                   all          8        266      0.482      0.443       0.42       0.29\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","\u001b[K     31/100         0G     0.8858     0.6687     0.9822        315        640: 100% ━━━━━━━━━━━━ 6/6 0.1it/s 1:45\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.7it/s 1.5s\n","                   all          8        266      0.423       0.53      0.459      0.314\n","\u001b[34m\u001b[1mEarlyStopping: \u001b[0mTraining stopped early as no improvement observed in last 25 epochs. Best results observed at epoch 6, best model saved as best.pt.\n","To update EarlyStopping(patience=25) pass a new patience value, i.e. `patience=300` or use `patience=0` to disable EarlyStopping.\n","\n","31 epochs completed in 0.903 hours.\n","Optimizer stripped from /content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/last.pt, 87.6MB\n","Optimizer stripped from /content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt, 87.6MB\n","\n","Validating /content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt...\n","Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cpu CPU (AMD EPYC 7B13)\n","Model summary (fused): 112 layers, 43,608,150 parameters, 0 gradients, 164.8 GFLOPs\n","\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% ━━━━━━━━━━━━ 1/1 0.6it/s 1.5s\n","                   all          8        266      0.689      0.531       0.58      0.401\n","               vehicle          8        233      0.726      0.605      0.629      0.441\n","                 human          7         33      0.653      0.456       0.53      0.361\n","Speed: 0.2ms preprocess, 170.7ms inference, 0.0ms loss, 14.2ms postprocess per image\n","Results saved to \u001b[1m/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]},{"cell_type":"code","source":["# To test on a video file from your Google Drive\n","# !yolo task=detect mode=predict model=\"/content/gdrive/My Drive/Yolo_Checkpoints/PV3/weights/best.pt\" conf=0.25 source=\"/content/gdrive/MyDrive/path/to/your/video.mp4\"\n","!yolo task=detect mode=predict model=\"/content/gdrive/My Drive/Yolo_Checkpoints/peds_vehicles/train/weights/best.pt\" conf=0.25 source=\"/content/gdrive/MyDrive/Datasets/peds_vehicles/traffic.mp4\"\n","# To test on a folder of images\n","# Make sure the path to the images is correct\n","# !yolo task=detect mode=predict model=\"/content/gdrive/My Drive/Yolo_Checkpoints/peds_vehicles/weights/best.pt\" conf=0.25 source=\"/content/gdrive/MyDrive/path/to/your/image_folder\""],"metadata":{"id":"b5t_gprFuA-G"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# testing on images\n","\n","!yolo task=track mode=predict model=\"/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt\" conf=0.25 source=\"/content/gdrive/MyDrive/Datasets/peds_vehicles/trf1.jpeg\"\n","!yolo task=track mode=predict model=\"/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt\" conf=0.25 source=\"/content/gdrive/MyDrive/Datasets/peds_vehicles/trf2.jpeg\"\n","!yolo task=track mode=predict model=\"/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt\" conf=0.25 source=\"/content/gdrive/MyDrive/Datasets/peds_vehicles/Pedestrains_8.jpeg\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j_PAPfq6Ehsd","executionInfo":{"status":"ok","timestamp":1758566119661,"user_tz":-330,"elapsed":25948,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"4464be55-0bb2-4f00-841f-d6e86ac440a9"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["WARNING ⚠️ invalid 'task=track', setting 'task=detect' and 'mode=track'. Valid tasks are ['classify', 'segment', 'pose', 'obb', 'detect'].\n","\n","    Arguments received: ['yolo', 'task=track', 'mode=predict', 'model=/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt', 'conf=0.25', 'source=/content/gdrive/MyDrive/Datasets/peds_vehicles/trf1.jpeg']. Ultralytics 'yolo' commands use the following syntax:\n","\n","        yolo TASK MODE ARGS\n","\n","        Where   TASK (optional) is one of ['classify', 'segment', 'pose', 'obb', 'detect']\n","                MODE (required) is one of ['val', 'benchmark', 'track', 'train', 'predict', 'export']\n","                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n","                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n","\n","    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n","        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n","\n","    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n","        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n","\n","    3. Val a pretrained detection model at batch-size 1 and image size 640:\n","        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n","\n","    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n","        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n","\n","    5. Ultralytics solutions usage\n","        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n","\n","    6. Run special commands:\n","        yolo help\n","        yolo checks\n","        yolo version\n","        yolo settings\n","        yolo copy-cfg\n","        yolo cfg\n","        yolo solutions help\n","\n","    Docs: https://docs.ultralytics.com\n","    Solutions: https://docs.ultralytics.com/solutions/\n","    Community: https://community.ultralytics.com\n","    GitHub: https://github.com/ultralytics/ultralytics\n","    .\n","\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['lap>=0.5.12'] not found, attempting AutoUpdate...\n","\n","\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success ✅ 0.5s\n","WARNING ⚠️ \u001b[31m\u001b[1mrequirements:\u001b[0m \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n","\n","Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 112 layers, 43,608,150 parameters, 0 gradients, 164.8 GFLOPs\n","\n","image 1/1 /content/gdrive/MyDrive/Datasets/peds_vehicles/trf1.jpeg: 480x640 37 vehicles, 6 humans, 98.0ms\n","Speed: 11.4ms preprocess, 98.0ms inference, 363.0ms postprocess per image at shape (1, 3, 480, 640)\n","Results saved to \u001b[1m/content/runs/detect/track\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/track\n","WARNING ⚠️ invalid 'task=track', setting 'task=detect' and 'mode=track'. Valid tasks are ['classify', 'detect', 'pose', 'obb', 'segment'].\n","\n","    Arguments received: ['yolo', 'task=track', 'mode=predict', 'model=/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt', 'conf=0.25', 'source=/content/gdrive/MyDrive/Datasets/peds_vehicles/trf2.jpeg']. Ultralytics 'yolo' commands use the following syntax:\n","\n","        yolo TASK MODE ARGS\n","\n","        Where   TASK (optional) is one of ['classify', 'detect', 'pose', 'obb', 'segment']\n","                MODE (required) is one of ['val', 'benchmark', 'train', 'track', 'predict', 'export']\n","                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n","                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n","\n","    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n","        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n","\n","    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n","        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n","\n","    3. Val a pretrained detection model at batch-size 1 and image size 640:\n","        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n","\n","    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n","        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n","\n","    5. Ultralytics solutions usage\n","        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n","\n","    6. Run special commands:\n","        yolo help\n","        yolo checks\n","        yolo version\n","        yolo settings\n","        yolo copy-cfg\n","        yolo cfg\n","        yolo solutions help\n","\n","    Docs: https://docs.ultralytics.com\n","    Solutions: https://docs.ultralytics.com/solutions/\n","    Community: https://community.ultralytics.com\n","    GitHub: https://github.com/ultralytics/ultralytics\n","    .\n","Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 112 layers, 43,608,150 parameters, 0 gradients, 164.8 GFLOPs\n","\n","image 1/1 /content/gdrive/MyDrive/Datasets/peds_vehicles/trf2.jpeg: 544x640 19 vehicles, 4 humans, 68.6ms\n","Speed: 2.4ms preprocess, 68.6ms inference, 129.4ms postprocess per image at shape (1, 3, 544, 640)\n","Results saved to \u001b[1m/content/runs/detect/track2\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/track\n","WARNING ⚠️ invalid 'task=track', setting 'task=detect' and 'mode=track'. Valid tasks are ['obb', 'segment', 'pose', 'classify', 'detect'].\n","\n","    Arguments received: ['yolo', 'task=track', 'mode=predict', 'model=/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt', 'conf=0.25', 'source=/content/gdrive/MyDrive/Datasets/peds_vehicles/Pedestrains_8.jpeg']. Ultralytics 'yolo' commands use the following syntax:\n","\n","        yolo TASK MODE ARGS\n","\n","        Where   TASK (optional) is one of ['obb', 'segment', 'pose', 'classify', 'detect']\n","                MODE (required) is one of ['export', 'predict', 'track', 'train', 'benchmark', 'val']\n","                ARGS (optional) are any number of custom 'arg=value' pairs like 'imgsz=320' that override defaults.\n","                    See all ARGS at https://docs.ultralytics.com/usage/cfg or with 'yolo cfg'\n","\n","    1. Train a detection model for 10 epochs with an initial learning_rate of 0.01\n","        yolo train data=coco8.yaml model=yolo11n.pt epochs=10 lr0=0.01\n","\n","    2. Predict a YouTube video using a pretrained segmentation model at image size 320:\n","        yolo predict model=yolo11n-seg.pt source='https://youtu.be/LNwODJXcvt4' imgsz=320\n","\n","    3. Val a pretrained detection model at batch-size 1 and image size 640:\n","        yolo val model=yolo11n.pt data=coco8.yaml batch=1 imgsz=640\n","\n","    4. Export a YOLO11n classification model to ONNX format at image size 224 by 128 (no TASK required)\n","        yolo export model=yolo11n-cls.pt format=onnx imgsz=224,128\n","\n","    5. Ultralytics solutions usage\n","        yolo solutions count or in ['crop', 'blur', 'workout', 'heatmap', 'isegment', 'visioneye', 'speed', 'queue', 'analytics', 'inference', 'trackzone'] source=\"path/to/video.mp4\"\n","\n","    6. Run special commands:\n","        yolo help\n","        yolo checks\n","        yolo version\n","        yolo settings\n","        yolo copy-cfg\n","        yolo cfg\n","        yolo solutions help\n","\n","    Docs: https://docs.ultralytics.com\n","    Solutions: https://docs.ultralytics.com/solutions/\n","    Community: https://community.ultralytics.com\n","    GitHub: https://github.com/ultralytics/ultralytics\n","    .\n","Ultralytics 8.3.203 🚀 Python-3.12.11 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n","Model summary (fused): 112 layers, 43,608,150 parameters, 0 gradients, 164.8 GFLOPs\n","\n","image 1/1 /content/gdrive/MyDrive/Datasets/peds_vehicles/Pedestrains_8.jpeg: 448x640 141 vehicles, 26 humans, 85.7ms\n","Speed: 3.8ms preprocess, 85.7ms inference, 194.3ms postprocess per image at shape (1, 3, 448, 640)\n","Results saved to \u001b[1m/content/runs/detect/track3\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/track\n"]}]},{"cell_type":"code","source":["!yolo task=detect mode=predict model=\"/content/gdrive/My Drive/Yolo_Checkpoints/PV3/train/weights/best.pt\" conf=0.25 source=\"/content/gdrive/MyDrive/Datasets/peds_vehicles/Pedestrains_8.jpeg\""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"x53m-8WkEwVo","executionInfo":{"status":"ok","timestamp":1758509310953,"user_tz":-330,"elapsed":2709,"user":{"displayName":"bt23105067 Anushak Bhardwaj","userId":"03721746902651564691"}},"outputId":"4e654bce-1740-484b-d72b-fd1596d49e06"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Ultralytics 8.3.202 🚀 Python-3.12.11 torch-2.8.0+cpu CPU (AMD EPYC 7B13)\n","Model summary (fused): 112 layers, 43,608,150 parameters, 0 gradients, 164.8 GFLOPs\n","\n","image 1/1 /content/gdrive/MyDrive/Datasets/peds_vehicles/Pedestrains_8.jpeg: 448x640 141 vehicles, 26 humans, 239.1ms\n","Speed: 2.1ms preprocess, 239.1ms inference, 14.0ms postprocess per image at shape (1, 3, 448, 640)\n","Results saved to \u001b[1m/content/runs/detect/predict3\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/predict\n"]}]}]}